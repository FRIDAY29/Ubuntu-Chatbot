{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMzv4-Z5bS5x"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import PyPDF2\n",
        "import spacy\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSrbmjCobS2i"
      },
      "outputs": [],
      "source": [
        "# Define functions for text extraction and embedding\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        for page_num in range(len(pdf_reader.pages)):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1yAK1HBbS0S"
      },
      "outputs": [],
      "source": [
        " #Path to your PDF file\n",
        "#pdf_path = '/content/Getting Started with Ubuntu 16.04.pdf'  # Adjust path as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXFmDoO8b4xe"
      },
      "outputs": [],
      "source": [
        "# Extract text from the PDF\n",
        "#pdf_text = extract_text_from_pdf(pdf_path)\n",
        "\n",
        "# Convert the text to a DataFrame\n",
        "#df = pd.DataFrame({'text': [pdf_text]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tvBaYw6fpWsw"
      },
      "outputs": [],
      "source": [
        "df1=pd.read_csv('/content/dialogueText_file1.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLSNgrz6tAkQ"
      },
      "outputs": [],
      "source": [
        "# prompt: store 30 percent of df1 in df\n",
        "\n",
        "df = df1.sample(frac=0.3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmtt6hUzb8uW"
      },
      "outputs": [],
      "source": [
        "# Load the custom embedding model\n",
        "class CustomEmbeddingModel:\n",
        "    def __init__(self, model_name):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        self.model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "    def embed_text(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            embeddings = self.model(**inputs).last_hidden_state.mean(dim=1)\n",
        "        return embeddings[0].numpy()\n",
        "\n",
        "embedding_model = CustomEmbeddingModel('/content/Embedding_model')  # Replace with your model name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zmdhpf2ocCgm"
      },
      "outputs": [],
      "source": [
        "# Load Spacy model for preprocessing\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def preprocess_text(text):\n",
        "    doc = nlp(text)\n",
        "    tokens = [token.lemma_.lower() for token in doc if token.text.lower() not in spacy.lang.en.stop_words.STOP_WORDS and token.is_alpha]\n",
        "    return ' '.join(tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vMJOkIGrcCdH"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing and embedding\n",
        "df['text'] = df['text'].apply(preprocess_text)\n",
        "df['text_embeddings'] = df['text'].apply(lambda x: embedding_model.embed_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDmygOAvcG9q"
      },
      "outputs": [],
      "source": [
        "# Create FAISS vector store\n",
        "documents = df['text'].tolist()\n",
        "embeddings = df['text_embeddings'].tolist()\n",
        "index = faiss.IndexFlatL2(len(embeddings[0]))\n",
        "index.add(np.array(embeddings))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1T7FiqkeCV5"
      },
      "outputs": [],
      "source": [
        "# Function to perform similarity search\n",
        "def search(query):\n",
        "    query_embedding = embedding_model.embed_text(query).reshape(1, -1)\n",
        "    _, indices = index.search(query_embedding, k=1)  # Retrieve top 1 result\n",
        "    return documents[indices[0][0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ0pXhI_eCQC"
      },
      "outputs": [],
      "source": [
        "# Function to generate a response\n",
        "def generate_response(prompt):\n",
        "    result = search(prompt)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0_eCjOheNS-"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xLHzZSCyeJFG"
      },
      "outputs": [],
      "source": [
        "# Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=gr.Textbox(label=\"Enter your query\", placeholder=\"Ask about Ubuntu...\"),\n",
        "    outputs=gr.Textbox(label=\"Response\"),\n",
        "    title=\"Ubuntu Manual Chatbot\",\n",
        "    description=\"Ask questions about the Ubuntu manual.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "2RxCJ43eePWH",
        "outputId": "86af6917-9113-4aee-e408-dc298e8a0a56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://bc0dcd839f0c2fc18b.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://bc0dcd839f0c2fc18b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Launch the Gradio interface\n",
        "iface.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}